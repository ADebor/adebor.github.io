{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIfhvRIqECcL+toi94wFm0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADebor/adebor.github.io/blob/master/notebooks/math0487_tp5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MATH0487 - TP5 - Régression\n",
        "## Notebook d'accompagnement\n",
        "### ULiège, Nov. 2023"
      ],
      "metadata": {
        "id": "Gfnui-itjVqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V86p-VpfQDoL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.datasets import load_iris\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice 1.4"
      ],
      "metadata": {
        "id": "VPARSu7AjTLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# paramètre de la régression logistique\n",
        "theta = 1\n",
        "\n",
        "# variable prédictive\n",
        "x = np.linspace(-3, 3, 100)\n",
        "\n",
        "# modèle logistique\n",
        "def logistic(x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# dérivée du modèle\n",
        "def logistic_prime(x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "'''  '''\n",
        "# log-odds\n",
        "def log_odds(x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# plots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex='col', figsize=(6, 4))\n",
        "ax1.plot(x, logistic(x), label='$\\mu$')\n",
        "ax1.set_ylabel('$\\mu(x)$, $F_X$')\n",
        "\n",
        "ax2.plot(x, logistic_prime(x))\n",
        "ax2.set_ylabel('$\\mu\\'(x)$, $f_X$')\n",
        "\n",
        "ax3.plot(x, log_odds(x))\n",
        "ax3.set_ylabel('$\\lambda(x)$')\n",
        "\n",
        "ax1.plot(x, stats.norm.cdf(x), label='$\\mathcal{N}(0, 1)$')\n",
        "ax2.plot(x, stats.norm.pdf(x))\n",
        "\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.suptitle(\"Comparaisons qualitatives\")\n",
        "fig.legend(loc='center right')"
      ],
      "metadata": {
        "id": "AUDgV7FEjT4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice 1.5"
      ],
      "metadata": {
        "id": "awBy2N8ejUUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Scikit-Learn"
      ],
      "metadata": {
        "id": "Bi8gfl60azQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chargeons les données\n",
        "data = load_iris()\n",
        "\n",
        "# ne considérons que deux classes d'observation\n",
        "idx = np.where(data.target != 2)\n",
        "X = data.data[:, :2][idx]\n",
        "y = data.target[idx]"
      ],
      "metadata": {
        "id": "zNhvVAbRLjJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualisons les données\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "scatter = ax.scatter(X[:, 0], X[:, 1], c=y, s=25)\n",
        "\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"best\", title=\"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.xlabel(\"Longueur des sépales\")\n",
        "plt.ylabel(\"Largeur des sépales\")"
      ],
      "metadata": {
        "id": "MUoxIqaAT51K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# créons une instance de LogisticRegression et estimons les paramètres\n",
        "logreg = LogisticRegression(fit_intercept=False, C=1e5) # on force l'intercept à zéro ici\n",
        "\"\"\"VOTRE CODE\"\"\"  # fit du modèle sur les données\n",
        "\n",
        "# traçons la limite décisionnelle du modèle \"fitté\"\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "DecisionBoundaryDisplay.from_estimator(\n",
        "    logreg,\n",
        "    X,\n",
        "    ax=ax,\n",
        "    response_method=\"predict\",\n",
        "    plot_method=\"pcolormesh\",\n",
        "    shading=\"auto\",\n",
        "    xlabel=\"Longueur des sépales\",\n",
        "    ylabel=\"Largeur des sépales\",\n",
        "    eps=0.5,\n",
        ")\n",
        "\n",
        "# ajoutons les données à la figure\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"best\", title=\"Classes\")\n",
        "ax.add_artist(legend1)"
      ],
      "metadata": {
        "id": "7JEMhTyhVSsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction des coefficients\n",
        "logreg.coef_"
      ],
      "metadata": {
        "id": "q2w2s2w6ViFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Maximisation de la vraisemblance"
      ],
      "metadata": {
        "id": "7QB_SUs8a-jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# supposition initiale\n",
        "theta0 = [0, 0]\n",
        "\n",
        "# fonction \"log-odds\"\n",
        "def log_odds(theta, x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# opposé de la fonction de vraisemblance\n",
        "def minus_likelihood(theta, x):\n",
        "  \"\"\"VOTRE CODE\"\"\""
      ],
      "metadata": {
        "id": "HscUH51DNvzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minimisation de l'opposé de la vraisemblance\n",
        "ret = minimize(fun=minus_likelihood, x0=theta0, args=X)"
      ],
      "metadata": {
        "id": "AuM9QUfKNv2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction des paramètres\n",
        "ret.x"
      ],
      "metadata": {
        "id": "Xk0f4cunNv5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Ascension de gradient"
      ],
      "metadata": {
        "id": "pcql11aMbFus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modèle logistique à deux paramètres\n",
        "def logistic2D(theta, x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# fonction score\n",
        "def score(theta, idx, x):\n",
        "  \"\"\"VOTRE CODE\"\"\""
      ],
      "metadata": {
        "id": "YpEFz1LOu1IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supposition initiale\n",
        "theta = [0, 0]\n",
        "\n",
        "# taux d'apprentissage (learning rate)\n",
        "lr = .01\n",
        "\n",
        "scores0 = []\n",
        "scores1 = []\n",
        "\n",
        "# ascension de gradient (tant que la fonction score n'est pas <= 0.001)\n",
        "while(abs(score(theta, 0, X)) > 1e-4 or abs(score(theta, 1, X)) > 1e-4):\n",
        "  score0 = score(theta, 0, X)\n",
        "  score1 = score(theta, 1, X)\n",
        "\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "  scores0.append(abs(score0))\n",
        "  scores1.append(abs(score1))\n",
        "\n",
        "# visualisation de la convergence\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.plot(scores0[80:])\n",
        "ax.plot(scores1[80:])\n",
        "ax.set_xlabel('itération $n$')\n",
        "ax.set_ylabel('score')"
      ],
      "metadata": {
        "id": "2iO3OUfru1K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction des paramètres\n",
        "theta"
      ],
      "metadata": {
        "id": "cTahqH-Tu1Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice 1.6"
      ],
      "metadata": {
        "id": "6P1VEMpEjUjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nombre de points de données\n",
        "n = 150\n",
        "\n",
        "# seed\n",
        "np.random.seed(1)\n",
        "\n",
        "# génération des variables prédictives\n",
        "x = np.random.uniform(low=-1.5, high=1.5, size=(n,1), )\n",
        "\n",
        "# loi de génération artificielle\n",
        "def f(x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# génération des observations artificielles\n",
        "y = f(x)\n",
        "\n",
        "# visualisation des données\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")"
      ],
      "metadata": {
        "id": "-nYcW46KC2C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# estimateur MLE\n",
        "theta = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation du modèle\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "x_model = np.linspace(-1.5, 1.5, n)\n",
        "plt.plot(x_model, theta*x_model, color='orange', label=\"$\\hat{y}$\")\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "v7ywq4VpjUpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction du paramètre\n",
        "theta"
      ],
      "metadata": {
        "id": "aNIvn7LKkJYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit avec scikit-learn\n",
        "reg = \"\"\"VOTRE CODE\"\"\""
      ],
      "metadata": {
        "id": "2H44bXOcjxNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction du paramètre\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "bsGEUCitkHfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loi prédictive de degré 3\n",
        "def f(x):\n",
        "  \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# génération des observations artificielles\n",
        "y = f(x)\n",
        "\n",
        "# visualisation des données\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")"
      ],
      "metadata": {
        "id": "BTX1qM_0FxyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# estimateur MLE\n",
        "theta = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation du modèle\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "x_model = np.linspace(-1.5, 1.5, n)\n",
        "plt.plot(x_model, theta*x_model, color='orange', label=\"$\\hat{y}$\")\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "RrLXMOCFH-PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajout d'une \"feature\" (x²)\n",
        "x_2d = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# estimation des paramètres\n",
        "reg = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation du modèle\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "x_model = np.linspace(-1.5, 1.5, n)\n",
        "x_model_2d = np.vstack((x_model, x_model**2)).transpose()\n",
        "\n",
        "plt.plot(x_model, reg.predict(x_model_2d), color='orange', label=\"$\\hat{y}$\")\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XpiAZEx2JMMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction des paramètres\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "1MBhbm9XmyP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficient de détermination\n",
        "\"\"\"VOTRE CODE\"\"\""
      ],
      "metadata": {
        "id": "2KMbyywVL6bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calcul des résidus de régression\n",
        "u = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "plt.scatter(x, u, s=.75)\n",
        "plt.xlabel(\"$y$\")\n",
        "plt.ylabel(\"$\\hat{u}$\")"
      ],
      "metadata": {
        "id": "8D_16tIuOlM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajout d'une \"feature\" (x^3)\n",
        "x_3d = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# estimation des paramètres\n",
        "reg = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation du modèle\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "x_model = np.linspace(-1.5, 1.5, n)\n",
        "x_model_3d = np.vstack((x_model, x_model**2, x_model**3)).transpose()\n",
        "\n",
        "plt.plot(x_model, reg.predict(x_model_3d), color='orange', label=\"$\\hat{y}$\")\n",
        "plt.scatter(x, y, s=.75)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "PCG3O4ZbPuAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction des paramètres\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "TVgXKsTKrd3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficient de détermination\n",
        "\"\"\"VOTRE CODE\"\"\""
      ],
      "metadata": {
        "id": "WOin7G7rrd6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calcul des résidus de régression\n",
        "u = \"\"\"VOTRE CODE\"\"\"\n",
        "\n",
        "# visualisation\n",
        "_, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "plt.scatter(x, u, s=.75)\n",
        "plt.xlabel(\"$y$\")\n",
        "plt.ylabel(\"$\\hat{u}$\")"
      ],
      "metadata": {
        "id": "AW2BcMnLrd-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}